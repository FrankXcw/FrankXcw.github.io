# 远程通信协议原理

### DNS服务

DNS(Domain Name System)，它和 HTTP 协议一样是位于应用层的协议，主要提供域名到 IP 的解析服务。

![image-20210304145502872](https://i.loli.net/2021/03/04/hxJPZi2AdYeuCVg.png)



### CDN加速

CDN（Content Delivery Network），表示的是内容分发网 络。CDN 其实就是一种网络缓存技术，能够把一些相对稳定的资源放到距离最终用户较近的 地方，一方面可以节省整个广域网的带宽消耗，另外一方面可以提升用户的访问速度，改进 用户体验。我们一般会把静态的文件（图片、脚本、静态页面）放到 CDN 中。



## HTTP 协议通信原理

**通信协议**：TCP 、UDP

**应用层协议**：Http、FTP、 DNS、SMTP、Telnet

### 分层模型

![image-20210304145548621](https://i.loli.net/2021/03/04/9HydYRqx8Bbi2cr.png)

**TCP/IP 四层模型**：应用层、传输层、网络层、网络接口层

**TCP/IP 五层模型**：应用层、传输层、网络层、数据链路层、物理层

**OSI 七层模型**：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层

请求发起过程，在 tcp/ip 四层网络模型中所做的事情

![image-20210304145620169](https://i.loli.net/2021/03/04/tWXfT8cnkdOMaiV.png)

接收端收到数据包以后的处理过程

![image-20210304145643993](https://i.loli.net/2021/03/04/WUlV3gATaCK1QOI.png)

### 分层负载 

#### 二层负载均衡

二层负载是针对 MAC，负载均衡服务器对外依然提供一个 VIP（虚 IP），集群中不同的机器 采用相同 IP 地址，但是机器的 MAC 地址不一样。当负载均衡服务器接受到请求之后，通过 改写报文的目标 MAC 地址的方式将请求转发到目标机器实现负载均衡 二层负载均衡会通过一个虚拟 MAC 地址接收请求，然后再分配到真实的 MAC 地址

**二层负载均衡会通过一个虚拟 MAC 地址接收请求，然后再分配到真实的 MAC 地址**

#### 三层负载均衡

三层负载是针对 IP，和二层负载均衡类似，负载均衡服务器对外依然提供一个 VIP（虚 IP）， 但是集群中不同的机器采用不同的 IP 地址。当负载均衡服务器接受到请求之后，根据不同的 负载均衡算法，通过 IP 将请求转发至不同的真实服务器

**三层负载均衡会通过一个虚拟 IP 地址接收请求，然后再分配到真实的 IP 地址**

#### 四层负载均衡

四层负载均衡工作在 OSI 模型的传输层，由于在传输层，只有 TCP/UDP 协议，这两种协议 中除了包含源 IP、目标 IP 以外，还包含源端口号及目的端口号。四层负载均衡服务器在接受 到客户端请求后，以后通过修改数据包的地址信息（IP+端口号）将流量转发到应用服务器。

**四层通过虚拟 IP + 端口接收请求，然后再分配到真实的服务器**

#### 七层负载均衡

七层负载均衡工作在 OSI 模型的应用层，应用层协议较多，常用 http、radius、dns 等。七层 负载就可以基于这些协议来负载。这些应用层协议中会包含很多有意义的内容。比如同一个 Web 服务器的负载均衡，除了根据 IP 加端口进行负载外，还可根据七层的 URL、浏览器类 别来决定是否要进行负载均衡

**七层通过虚拟的 URL 或主机名接收请求，然后再分配到真实的服务器**

## TCP/IP 协议的深入分析

### TCP 握手协议 

![image-20210304145714554](https://i.loli.net/2021/03/04/EL8f31G2FBQkwbu.png)

**第 一 次 握 手** (SYN=1, seq=x) 客 户 端 发 送 一 个 TCP 的 SYN 标志 位置 1 的包，指明客户端打算连接的服务器的端口，以及 初始序号 X,保存 在 包 头 的 序 列 号 (Sequence Number)字段里。 发送完毕后，客户端 进 入 SYN_SEND 状态。

**第 二 次 握 手** (SYN=1, ACK=1, seq=y, ACKnum=x+1): 服务器发回确认包 (ACK) 应 答 。 即 SYN 标志位和 ACK 标 志 位 均 为 1。服务器端选择自己 ISN 序列号，放 到 Seq 域里，同时将确认序 号 (Acknowledgeme nt Number)设置为客户的 ISN 加 1， 即 X+1。 发送完毕后，服务 器 端 进 入 SYN_RCVD 状态。

**第 三 次 握 手** (ACK=1 ， ACKnum=y+1) 客户端再次发送确 认包(ACK)，SYN 标 志位为 0，ACK 标 志位为 1，并且把服 务器发来 ACK 的 序号字段+1，放在 确定字段中发送给 对方，并且在数据 段放写 ISN 发完毕 后 ， 客 户 端 进 入 ESTABLISHED 状 态，当服务器端接 收到这个包时，也 进 入 ESTABLISHED 状 态，TCP 握手结束。

### SYN 攻击 

在三次握手过程中，Server 发送 SYN-ACK 之后，收到 Client 的 ACK 之前的 TCP 连接称为 半连接（half-open connect），此时 Server 处于 SYN_RCVD 状态，当收到 ACK 后，Server 转入 ESTABLISHED 状态。**SYN 攻击就是 Client 在短时间内伪造大量不存在的 IP 地址，并向 Server 不断地发送 SYN 包，Server 回复确认包，并等待 Client 的确认，由于源地址是不存 在的，因此，Server 需要不断重发直至超时，这些伪造的 SYN 包将产时间占用未连接队 列，导致正常的 SYN 请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪**。SYN 攻 击时一种典型的 DDOS 攻击，检测 SYN 攻击的方式非常简单，即当 Server 上有大量半连接 状态且源 IP 地址是随机的，则可以断定遭到 SYN 攻击了

### TCP 四次挥手协议

四次挥手表示 TCP 断开连接的时候,需要客户端和服务端总共发送 4 个包以确认连接的断开； 客户端或服务器均可主动发起挥手动作(因为 **TCP 是一个全双工协议**)，在 socket 编程中， 任何一方执行 close() 操作即可产生挥手操作。

**单工**：数据传输只支持数据在一个方 向上传输 

**半双工**：数据传输允许数据在两个方 向上传输，但是在某一时刻，只允许 在一个方向上传输，实际上有点像切 换方向的单工通信 

**全双工**：数据通信允许数据同时在两 个方向上传输，因此全双工是两个单 工通信方式的结合，它要求发送设备 和接收设备都有独立的接收和发送 能力

![image-20210304145741326](https://i.loli.net/2021/03/04/b4hvKsUfgWnIB8d.png)

**第一次挥手**(FIN=1，seq=x) 假设客户端想要关闭连接，客户端发送一个 FIN 标志位置为 1 的包，表示自己已经没有数据 可以发送了，但是仍然可以接受数据。发送完毕后，客户端进入 FIN_WAIT_1 状态。 

**第二次挥手**(ACK=1，ACKnum=x+1) 服务器端确认客户端的 FIN 包，发送一个确认包，表明自己接受到了客户端关闭连接的请求， 但还没有准备好关闭连接。发送完毕后，服务器端进入 CLOSE_WAIT 状态，客户端接收到这 个确认包之后，进入 FIN_WAIT_2 状态，等待服务器端关闭连接。 

**第三次挥手**(FIN=1，seq=w) 服务器端准备好关闭连接时，向客户端发送结束连接请求，FIN 置为 1。发送完毕后，服务器 端进入 LAST_ACK 状态，等待来自客户端的最后一个 ACK。 

**第四次挥手**(ACK=1，ACKnum=w+1) 客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入 TIME_WAIT 状态，等待 可能出现的要求重传的 ACK 包。 服务器端接收到这个确认包之后，关闭连接，进入 CLOSED 状态。 客户端等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime） 之后，没有收到服务器端的 ACK，认为服务器端已经正常关闭连接，于是自己也关闭连接， 进入 CLOSED 状态。

假设 Client 端发起中断连接请求，也就是发送 FIN 报文。Server 端接到 FIN 报文后，意思是 说"我 Client 端没有数据要发给你了"，但是如果你还有数据没有发送完成，则不必急着关闭 Socket，可以继续发送数据。所以你先发送 ACK，"告诉 Client 端，你的请求我收到了，但是 我还没准备好，请继续你等我的消息"。这个时候 Client 端就进入 FIN_WAIT 状态，继续等待 Server 端的 FIN 报文。当 Server 端确定数据已发送完成，则向 Client 端发送 FIN 报文，"告 诉 Client 端，好了，我这边数据发完了，准备好关闭连接了"。Client 端收到 FIN 报文后，"就 知道可以关闭连接了，但是他还是不相信网络，怕 Server 端不知道要关闭，所以发送 ACK 后 进入 TIME_WAIT 状态，如果 Server 端没有收到 ACK 则可以重传。“，Server 端收到 ACK 后， "就知道可以断开连接了"。Client 端等待了 2MSL 后依然没有收到回复，则证明 Server 端已 正常关闭，那好，我 Client 端也可以关闭连接了。Ok，TCP 连接就这样关闭了！

## 使用协议进行通信

tcp 连接建立以后，就可以基于这个连接通道来发送和接受消息了，TCP、UDP 都是在基于 Socket 概念上为某类应用场景而扩展出的传输协议，那么什么是 socket 呢？socket 是一种 抽象层，应用程序通过它来发送和接收数据，就像应用程序打开一个文件句柄，把数据读写到磁盘上一样。使用 socket 可以把应用程序添加到网络中，并与处于同一个网络中的其他应 用程序进行通信。不同类型的 Socket 与不同类型的底层协议簇有关联。主要的 socket 类型 为流套接字（stream socket）和数据报文套接字（datagram socket）。 stream socket 把 TCP 作为端对端协议（底层使用 IP 协议），提供一个可信赖的字节流服务。数据报文套接字 （datagram socket）使用 UDP 协议（底层同样使用 IP 协议）提供了一种“尽力而为”的数据 报文服务。

![image-20210305104910330](https://i.loli.net/2021/03/05/RZkWbghFCrPucnY.png)

### socket链接建立以及通信的模型

![image-20210305105006227](https://i.loli.net/2021/03/05/ItOiHYvGZUMBXgq.png)

### 理解 TCP 的通信原理及 IO 阻塞

对于 TCP 通信来说，每个 TCP Socket 的内核中都有一个发送缓冲区和一个接收缓冲 区，TCP 的全双工的工作模式及 TCP 的滑动窗口就是依赖于这两个独立的 Buffer 和该 Buffer 的填充状态。 接收缓冲区把数据缓存到内核，若应用进程一直没有调用 Socket 的 read 方法进行读取，那 么该数据会一直被缓存在接收缓冲区内。不管进程是否读取 Socket，对端发来的数据都会经 过内核接收并缓存到 Socket 的内核接收缓冲区。 read 所要做的工作，就是把内核接收缓冲区中的数据复制到应用层用户的 Buffer 里。 进程调用 Socket 的 send 发送数据的时候，一般情况下是将数据从应用层用户的 Buffer 里复 制到 Socket 的内核发送缓冲区，然后 send 就会在上层返回。换句话说，send 返回时，数据 不一定会被发送到对端。

![image-20210305105333288](https://i.loli.net/2021/03/05/HRdsveh7fqGBK8J.png)

前面我们提到，Socket 的接收缓冲区被 TCP 用来缓存网络上收到的数据，一直保存到应用进 程读走为止。如果应用进程一直没有读取，那么 Buffer 满了以后，出现的情况是：通知对端 TCP 协议中的窗口关闭，保证 TCP 接收缓冲区不会移除，保证了 TCP 是可靠传输的。如果对 方无视窗口大小发出了超过窗口大小的数据，那么接收方会把这些数据丢弃。

#### 滑动窗口协议

这个过程中涉及到了 TCP 的滑动窗口协议，滑动窗口（Sliding window）是一种流量控制技 术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道 网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动 窗口机制来解决此问题；发送和接受方都会维护一个数据帧的序列，这个序列被称作窗口

#### 发送窗口

就是发送端允许连续发送的幀的序号表。 发送端可以不等待应答而连续发送的最大幀数称为发送窗口的尺寸。

#### 接收窗口

接收方允许接收的幀的序号表，凡落在 接收窗口内的幀，接收方都必须处理，落在接收窗口 外的幀被丢弃。 接收方每次允许接收的幀数称为接收窗口的尺寸。

在线滑动窗口演示功能 https://media.pearsoncmg.com/aw/ecs_kurose_compnetwork_7/cw/content/interactiveanimations/selective-repeat-protocol/index.html

## 阻塞

了解了基本通信原理以后，我们再来思考一个问题，在前面的代码演示中，我们通过 **socket.accept 去接收一个客户端请求，accept 是一个阻塞的方法**，意味着 TCP 服务器一次只能处理一个客户端请求，当一个客户端向一个已经被其他客户端占用的服务器发送连接请 求时，虽然在连接建立后可以向服务端发送数据，但是在服务端处理完之前的请求之前，却 不会对新的客户端做出响应，这种类型的服务器称为“迭代服务器”。迭代服务器是按照顺序处 理客户端请求，也就是服务端必须要处理完前一个请求才能对下一个客户端的请求进行响应。 但是在实际应用中，我们不能接收这样的处理方式。所以我们需要一种方法可以独立处理每 一个连接，并且他们之间不会相互干扰。而 Java 提供的多线程技术刚好满足这个需求，这个 机制使得服务器能够方便处理多个客户端的请求。

### 一个客户端对应一个线程

为每个客户端创建一个线程实际上会存在一些弊端，因为**创建一个线程需要占用 CPU 的资 源和内存资源**。另外，随着线程数增加，系统资源将会成为瓶颈最终达到一个不可控的状 态，所以我们还可以通过线程池来实现多个客户端请求的功能，因为线程池是可控的。

![image-20210305105756976](https://i.loli.net/2021/03/05/hVT6152xs7IbZcu.png)

#### 非阻塞模型 

上面这种模型虽然优化了 IO 的处理方式，但是，不管是线程池还是单个线程，线程本身的处 理个数是有限制的，对于操作系统来说，如果线程数太多会造成 CPU 上下文切换的开销。因 此这种方式不能解决根本问题

#### 阻塞 IO

是当客户端的数据从网卡缓冲区复制到内核缓冲区之前，服务端会一直阻塞。以socket接口为例， 进程空间中调用 recvfrom，进程从调用 recvfrom 开始到它返回的整段时间内都是被阻塞的， 因此被成为阻塞 IO 模型

![image-20210305124129811](https://i.loli.net/2021/03/05/4KIc8xCtJm1wviB.png)

#### 非阻塞 IO

如果我们希望这台服务器能够处理更多的连接，怎么去优化呢？ 我们第一时间想到的应该是如何保证这个阻塞变成非阻塞吧。所以就引入了非阻塞 IO 模型， 非阻塞 IO 模型的原理很简单，就是进程空间调用 recvfrom，如果这个时候内核缓冲区没有数据的话，就直接返回一个 EWOULDBLOCK 错误，然后应用程序通过不断轮询来检查这个 状态状态，看内核是不是有数据过来。

![image-20210305124244571](https://i.loli.net/2021/03/05/fT8RSiKL6wPChdV.png)

#### I/O 复用模型

我们前面讲的非阻塞仍然需要进程不断的轮询重试。能不能实现当数据可读了以后给程序一 个通知呢？所以这里引入了一个 IO 多路复用模型，I/O 多路复用的本质是通过一种机制（系统内核缓冲 I/O 数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作

【*什么是 fd：在 linux 中，内核把所有的外部设备都当成是一个文件来操作，对一个文件的读 写会调用内核提供的系统命令，返回一个 fd(文件描述符)。而对于一个 socket 的读写也会有 相应的文件描述符，成为 socketfd*】

 **IO 多路复用方式**：select、poll、epoll

**select**：进程可以通过把一个或者多个 fd 传递给 select 系统调用，进程会阻塞在 select 操作 上，这样 select 可以帮我们检测多个 fd 是否处于就绪状态。

这个模式有二个**缺点** 

1. 由于他能够同时监听多个文件描述符，假如说有 1000 个，这个时候如果其中一个 fd 处于 就绪状态了，那么当前进程需要线性轮询所有的 fd，也就是监听的 fd 越多，性能开销越大。 
2. 同时，select 在单个进程中能打开的 fd 是有限制的，默认是1024，对于那些需要支持单机 上万的 TCP 连接来说确实有点少

**epoll**：linux 还提供了 epoll 的系统调用，epoll 是基于**事件驱动**方式来**代替顺序扫描**，因此性能相对来说更高，主要原理是，当被监听的 fd 中，有 fd 就绪时，会告知当前进程具体哪一 个 fd 就绪，那么当前进程只需要去从指定的 fd 上读取数据即可。另外，epoll 所能支持的 fd 上线是操作系统的最大文件句柄，这个数字要远远大于 1024

*【由于 epoll 能够通过事件告知应用进程哪个 fd 是可读的，所以我们也称这种 IO 为异步非 阻塞 IO，当然它是伪异步的，因为它还需要去把数据从内核同步复制到用户空间中，真正的 异步非阻塞，应该是数据已经完全准备好了，我只需要从用户空间读就行】*

![image-20210305124818243](https://i.loli.net/2021/03/05/rH5b3qDaAcEzkUW.png)

**多路复用的好处** 

I/O 多路复用可以通过把**多个 I/O 的阻塞复用到同一个 select 的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求**。它的最大优势是**系统开销小**，并且**不需要创建新的进程或者线程，**降低了系统的资源开销

### 一台机器理论能支持的连接数 

**以 linux 服务器为例，实际的连接数还取决于**

1. **内存大小**（因为每个 TCP 连接都要占用一定的内存）、

2. **文件句柄限制**，每一个 tcp 连接都需要占一个文件描述符，一旦这个文件描述符使用完了， 新来的连接会返回一个“Can’t open so many files”的异常。如果大家知道对于操作系统最 大可以打开的文件数限制，就知道怎么去调整这个限制

   ​    a. 可以执行【ulimit -n】得到当前一个进程最大能打开 1024 个文件，所以你要采用此默 认配置最多也就		可以并发上千个 TCP 连接。

   ​	b. 可以通过【vim /etc/security/limits.conf】去修改系统最大文件打开数的限制 * soft nofile 2048 * hard 		nofile 2048 * 表示修改所有用户限制、soft/hard 表示软限制还是硬限制，2048 表示修改以后的值 

   ​	c. 可以通过【cat /proc/sys/fs/file-max】查看 linux 系统级最大打开文件数限制，表示当 前这个服务器最		多能同时打开多少个文件 当然，这块还有其他很多的优化的点，这里不是这节课的目标 

3. 带宽资源的限制